{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386b2775-1ab5-4b4a-8201-253f2fcd69c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:40:31.754956: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:40:31.755005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44107ec-fb56-4724-b5ca-9e8ab79b0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
    "num_epochs = 200 # we iterate 200 times over the entire training set\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the dense layer with probability 0.5\n",
    "hidden_size = 512 # the dense layer will have 512 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a9a0ef-1316-4aba-bddc-b1e2d0c8a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # fetch CIFAR-10 data\n",
    "num_train, depth, height, width = X_train.shape # there are 50000 training examples in CIFAR-10\n",
    "num_test = X_test.shape[0] # there are 10000 test examples in CIFAR-10\n",
    "num_classes = np.unique(y_train).shape[0] # there are 10 image classes\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train) # Normalise data to [0, 1] range\n",
    "X_test /= np.max(X_train) # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fc8909-d810-4f83-9d01-5d57d7aa8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(inp)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding = 'same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c0a49a-ce0f-484d-95ff-f538e2440d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 22:09:42.087104: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 552960000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.8960 - accuracy: 0.2828 - val_loss: 1.6592 - val_accuracy: 0.3806\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6931 - accuracy: 0.3713 - val_loss: 1.5663 - val_accuracy: 0.4278\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6200 - accuracy: 0.4000 - val_loss: 1.4793 - val_accuracy: 0.4564\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.5733 - accuracy: 0.4206 - val_loss: 1.4397 - val_accuracy: 0.4708\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5370 - accuracy: 0.4353 - val_loss: 1.4277 - val_accuracy: 0.4732\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.5143 - accuracy: 0.4460 - val_loss: 1.4133 - val_accuracy: 0.4860\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4839 - accuracy: 0.4587 - val_loss: 1.4019 - val_accuracy: 0.4930\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4669 - accuracy: 0.4660 - val_loss: 1.3828 - val_accuracy: 0.4922\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4393 - accuracy: 0.4769 - val_loss: 1.3324 - val_accuracy: 0.5158\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4301 - accuracy: 0.4827 - val_loss: 1.3321 - val_accuracy: 0.5164\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4148 - accuracy: 0.4879 - val_loss: 1.3251 - val_accuracy: 0.5186\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4076 - accuracy: 0.4918 - val_loss: 1.3017 - val_accuracy: 0.5330\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3941 - accuracy: 0.4947 - val_loss: 1.2852 - val_accuracy: 0.5444\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3824 - accuracy: 0.4992 - val_loss: 1.2885 - val_accuracy: 0.5378\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3657 - accuracy: 0.5044 - val_loss: 1.2799 - val_accuracy: 0.5390\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3597 - accuracy: 0.5118 - val_loss: 1.2676 - val_accuracy: 0.5512\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3425 - accuracy: 0.5159 - val_loss: 1.2795 - val_accuracy: 0.5412\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3440 - accuracy: 0.5154 - val_loss: 1.2478 - val_accuracy: 0.5540\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3358 - accuracy: 0.5212 - val_loss: 1.2615 - val_accuracy: 0.5442\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3194 - accuracy: 0.5270 - val_loss: 1.2573 - val_accuracy: 0.5528\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3152 - accuracy: 0.5258 - val_loss: 1.2221 - val_accuracy: 0.5700\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3170 - accuracy: 0.5307 - val_loss: 1.2421 - val_accuracy: 0.5504\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3068 - accuracy: 0.5274 - val_loss: 1.2377 - val_accuracy: 0.5620\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2985 - accuracy: 0.5375 - val_loss: 1.2336 - val_accuracy: 0.5596\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2973 - accuracy: 0.5352 - val_loss: 1.2173 - val_accuracy: 0.5680\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2893 - accuracy: 0.5354 - val_loss: 1.2285 - val_accuracy: 0.5588\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2882 - accuracy: 0.5355 - val_loss: 1.2123 - val_accuracy: 0.5626\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2786 - accuracy: 0.5430 - val_loss: 1.2294 - val_accuracy: 0.5588\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2809 - accuracy: 0.5406 - val_loss: 1.2161 - val_accuracy: 0.5650\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2723 - accuracy: 0.5450 - val_loss: 1.2119 - val_accuracy: 0.5674\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2690 - accuracy: 0.5465 - val_loss: 1.2183 - val_accuracy: 0.5678\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2705 - accuracy: 0.5449 - val_loss: 1.2131 - val_accuracy: 0.5710\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2595 - accuracy: 0.5474 - val_loss: 1.2154 - val_accuracy: 0.5736\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2560 - accuracy: 0.5502 - val_loss: 1.2140 - val_accuracy: 0.5704\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2646 - accuracy: 0.5490 - val_loss: 1.2168 - val_accuracy: 0.5684\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2608 - accuracy: 0.5489 - val_loss: 1.1937 - val_accuracy: 0.5796\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2457 - accuracy: 0.5555 - val_loss: 1.2018 - val_accuracy: 0.5764\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2470 - accuracy: 0.5540 - val_loss: 1.2099 - val_accuracy: 0.5732\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2419 - accuracy: 0.5552 - val_loss: 1.2026 - val_accuracy: 0.5720\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2422 - accuracy: 0.5557 - val_loss: 1.1750 - val_accuracy: 0.5706\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2371 - accuracy: 0.5574 - val_loss: 1.2383 - val_accuracy: 0.5538\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2414 - accuracy: 0.5525 - val_loss: 1.1863 - val_accuracy: 0.5860\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2316 - accuracy: 0.5573 - val_loss: 1.1837 - val_accuracy: 0.5766\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2271 - accuracy: 0.5612 - val_loss: 1.1997 - val_accuracy: 0.5750\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2216 - accuracy: 0.5655 - val_loss: 1.1941 - val_accuracy: 0.5750\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2261 - accuracy: 0.5622 - val_loss: 1.1941 - val_accuracy: 0.5758\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2282 - accuracy: 0.5610 - val_loss: 1.1981 - val_accuracy: 0.5702\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2237 - accuracy: 0.5618 - val_loss: 1.2045 - val_accuracy: 0.5758\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2194 - accuracy: 0.5642 - val_loss: 1.2198 - val_accuracy: 0.5722\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2203 - accuracy: 0.5612 - val_loss: 1.1871 - val_accuracy: 0.5742\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2138 - accuracy: 0.5651 - val_loss: 1.1905 - val_accuracy: 0.5756\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2183 - accuracy: 0.5664 - val_loss: 1.1946 - val_accuracy: 0.5786\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2135 - accuracy: 0.5694 - val_loss: 1.1880 - val_accuracy: 0.5796\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2132 - accuracy: 0.5673 - val_loss: 1.1997 - val_accuracy: 0.5752\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2141 - accuracy: 0.5672 - val_loss: 1.1929 - val_accuracy: 0.5726\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2039 - accuracy: 0.5702 - val_loss: 1.1946 - val_accuracy: 0.5732\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2124 - accuracy: 0.5648 - val_loss: 1.1975 - val_accuracy: 0.5812\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2126 - accuracy: 0.5680 - val_loss: 1.1796 - val_accuracy: 0.5766\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1994 - accuracy: 0.5719 - val_loss: 1.1742 - val_accuracy: 0.5814\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2038 - accuracy: 0.5702 - val_loss: 1.1889 - val_accuracy: 0.5758\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1969 - accuracy: 0.5709 - val_loss: 1.1943 - val_accuracy: 0.5726\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2041 - accuracy: 0.5710 - val_loss: 1.1809 - val_accuracy: 0.5808\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1991 - accuracy: 0.5701 - val_loss: 1.1938 - val_accuracy: 0.5814\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1924 - accuracy: 0.5736 - val_loss: 1.2008 - val_accuracy: 0.5784\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1980 - accuracy: 0.5713 - val_loss: 1.1857 - val_accuracy: 0.5868\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1888 - accuracy: 0.5771 - val_loss: 1.1879 - val_accuracy: 0.5802\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1957 - accuracy: 0.5720 - val_loss: 1.1909 - val_accuracy: 0.5752\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1935 - accuracy: 0.5755 - val_loss: 1.1864 - val_accuracy: 0.5818\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1928 - accuracy: 0.5747 - val_loss: 1.1728 - val_accuracy: 0.5844\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1873 - accuracy: 0.5784 - val_loss: 1.1931 - val_accuracy: 0.5770\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1876 - accuracy: 0.5751 - val_loss: 1.1807 - val_accuracy: 0.5898\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1902 - accuracy: 0.5777 - val_loss: 1.1979 - val_accuracy: 0.5856\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1849 - accuracy: 0.5803 - val_loss: 1.1852 - val_accuracy: 0.5792\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1824 - accuracy: 0.5794 - val_loss: 1.1881 - val_accuracy: 0.5834\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1831 - accuracy: 0.5776 - val_loss: 1.1908 - val_accuracy: 0.5708\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1803 - accuracy: 0.5794 - val_loss: 1.1725 - val_accuracy: 0.5892\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1813 - accuracy: 0.5791 - val_loss: 1.1886 - val_accuracy: 0.5818\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1807 - accuracy: 0.5801 - val_loss: 1.1727 - val_accuracy: 0.5836\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1824 - accuracy: 0.5790 - val_loss: 1.1875 - val_accuracy: 0.5740\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1795 - accuracy: 0.5788 - val_loss: 1.1776 - val_accuracy: 0.5830\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1714 - accuracy: 0.5826 - val_loss: 1.1804 - val_accuracy: 0.5810\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1713 - accuracy: 0.5827 - val_loss: 1.1946 - val_accuracy: 0.5836\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1785 - accuracy: 0.5796 - val_loss: 1.1793 - val_accuracy: 0.5896\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1750 - accuracy: 0.5818 - val_loss: 1.1768 - val_accuracy: 0.5912\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1826 - accuracy: 0.5821 - val_loss: 1.1778 - val_accuracy: 0.5872\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1732 - accuracy: 0.5818 - val_loss: 1.1945 - val_accuracy: 0.5790\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1705 - accuracy: 0.5827 - val_loss: 1.1712 - val_accuracy: 0.5906\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1699 - accuracy: 0.5823 - val_loss: 1.1586 - val_accuracy: 0.5922\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1725 - accuracy: 0.5859 - val_loss: 1.1807 - val_accuracy: 0.5926\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1627 - accuracy: 0.5834 - val_loss: 1.1700 - val_accuracy: 0.5896\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1634 - accuracy: 0.5858 - val_loss: 1.1843 - val_accuracy: 0.5850\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1676 - accuracy: 0.5837 - val_loss: 1.1608 - val_accuracy: 0.6040\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1646 - accuracy: 0.5846 - val_loss: 1.1991 - val_accuracy: 0.5754\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1645 - accuracy: 0.5849 - val_loss: 1.1780 - val_accuracy: 0.5942\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1630 - accuracy: 0.5882 - val_loss: 1.1595 - val_accuracy: 0.5934\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1687 - accuracy: 0.5837 - val_loss: 1.1750 - val_accuracy: 0.5962\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1650 - accuracy: 0.5838 - val_loss: 1.1603 - val_accuracy: 0.5884\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1614 - accuracy: 0.5882 - val_loss: 1.1636 - val_accuracy: 0.5860\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1614 - accuracy: 0.5894 - val_loss: 1.1704 - val_accuracy: 0.5912\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1628 - accuracy: 0.5861 - val_loss: 1.1536 - val_accuracy: 0.5936\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1590 - accuracy: 0.5894 - val_loss: 1.1670 - val_accuracy: 0.5978\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1623 - accuracy: 0.5869 - val_loss: 1.1797 - val_accuracy: 0.5792\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1640 - accuracy: 0.5830 - val_loss: 1.1645 - val_accuracy: 0.5908\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1563 - accuracy: 0.5930 - val_loss: 1.1675 - val_accuracy: 0.5854\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1476 - accuracy: 0.5935 - val_loss: 1.1613 - val_accuracy: 0.5892\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.1477 - accuracy: 0.5925 - val_loss: 1.1707 - val_accuracy: 0.5930\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1548 - accuracy: 0.5914 - val_loss: 1.1397 - val_accuracy: 0.5998\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1561 - accuracy: 0.5926 - val_loss: 1.1725 - val_accuracy: 0.5924\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1575 - accuracy: 0.5889 - val_loss: 1.1985 - val_accuracy: 0.5944\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1565 - accuracy: 0.5912 - val_loss: 1.1662 - val_accuracy: 0.5962\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1539 - accuracy: 0.5927 - val_loss: 1.1647 - val_accuracy: 0.5932\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1478 - accuracy: 0.5911 - val_loss: 1.1836 - val_accuracy: 0.5934\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1630 - accuracy: 0.5865 - val_loss: 1.1692 - val_accuracy: 0.5930\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1487 - accuracy: 0.5909 - val_loss: 1.1652 - val_accuracy: 0.5858\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1509 - accuracy: 0.5905 - val_loss: 1.1718 - val_accuracy: 0.5892\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1431 - accuracy: 0.5926 - val_loss: 1.1580 - val_accuracy: 0.5968\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1476 - accuracy: 0.5926 - val_loss: 1.1457 - val_accuracy: 0.5970\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1508 - accuracy: 0.5924 - val_loss: 1.1605 - val_accuracy: 0.5950\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1500 - accuracy: 0.5906 - val_loss: 1.1496 - val_accuracy: 0.5956\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1548 - accuracy: 0.5929 - val_loss: 1.1659 - val_accuracy: 0.5920\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1443 - accuracy: 0.5942 - val_loss: 1.1825 - val_accuracy: 0.5894\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1386 - accuracy: 0.5942 - val_loss: 1.1581 - val_accuracy: 0.5958\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1423 - accuracy: 0.5933 - val_loss: 1.1651 - val_accuracy: 0.5906\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1491 - accuracy: 0.5899 - val_loss: 1.1577 - val_accuracy: 0.5988\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1448 - accuracy: 0.5952 - val_loss: 1.1467 - val_accuracy: 0.5988\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1386 - accuracy: 0.5963 - val_loss: 1.1680 - val_accuracy: 0.5908\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1340 - accuracy: 0.5983 - val_loss: 1.1662 - val_accuracy: 0.5954\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1520 - accuracy: 0.5923 - val_loss: 1.1571 - val_accuracy: 0.5932\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1416 - accuracy: 0.5958 - val_loss: 1.1737 - val_accuracy: 0.5858\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1409 - accuracy: 0.5980 - val_loss: 1.1570 - val_accuracy: 0.5972\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1396 - accuracy: 0.5986 - val_loss: 1.1473 - val_accuracy: 0.6020\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1415 - accuracy: 0.5988 - val_loss: 1.1560 - val_accuracy: 0.5926\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1423 - accuracy: 0.5950 - val_loss: 1.1778 - val_accuracy: 0.5980\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1413 - accuracy: 0.5952 - val_loss: 1.1688 - val_accuracy: 0.5844\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1448 - accuracy: 0.5957 - val_loss: 1.1625 - val_accuracy: 0.5934\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1360 - accuracy: 0.5982 - val_loss: 1.1569 - val_accuracy: 0.5978\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1441 - accuracy: 0.5958 - val_loss: 1.1507 - val_accuracy: 0.5956\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1412 - accuracy: 0.5960 - val_loss: 1.1531 - val_accuracy: 0.6068\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1347 - accuracy: 0.5964 - val_loss: 1.1691 - val_accuracy: 0.5972\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1356 - accuracy: 0.5986 - val_loss: 1.1952 - val_accuracy: 0.5798\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1383 - accuracy: 0.5948 - val_loss: 1.1548 - val_accuracy: 0.5974\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1409 - accuracy: 0.5968 - val_loss: 1.1684 - val_accuracy: 0.5866\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1414 - accuracy: 0.5963 - val_loss: 1.1499 - val_accuracy: 0.5968\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1442 - accuracy: 0.5964 - val_loss: 1.1537 - val_accuracy: 0.5942\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1301 - accuracy: 0.6017 - val_loss: 1.1607 - val_accuracy: 0.5902\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1383 - accuracy: 0.5967 - val_loss: 1.1664 - val_accuracy: 0.5986\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1366 - accuracy: 0.5983 - val_loss: 1.1385 - val_accuracy: 0.5998\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1386 - accuracy: 0.5958 - val_loss: 1.1502 - val_accuracy: 0.5996\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1318 - accuracy: 0.5992 - val_loss: 1.1532 - val_accuracy: 0.6022\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1285 - accuracy: 0.6006 - val_loss: 1.1589 - val_accuracy: 0.5976\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1324 - accuracy: 0.5982 - val_loss: 1.1716 - val_accuracy: 0.5980\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1345 - accuracy: 0.5989 - val_loss: 1.1646 - val_accuracy: 0.5898\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1307 - accuracy: 0.6015 - val_loss: 1.1512 - val_accuracy: 0.6062\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1298 - accuracy: 0.5997 - val_loss: 1.1600 - val_accuracy: 0.5928\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1340 - accuracy: 0.5996 - val_loss: 1.1570 - val_accuracy: 0.5998\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1342 - accuracy: 0.5996 - val_loss: 1.1357 - val_accuracy: 0.6110\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1363 - accuracy: 0.6001 - val_loss: 1.1398 - val_accuracy: 0.6072\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1319 - accuracy: 0.6013 - val_loss: 1.1788 - val_accuracy: 0.5932\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1322 - accuracy: 0.5997 - val_loss: 1.1695 - val_accuracy: 0.5902\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1317 - accuracy: 0.6042 - val_loss: 1.1576 - val_accuracy: 0.6034\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1219 - accuracy: 0.6042 - val_loss: 1.1711 - val_accuracy: 0.5992\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1294 - accuracy: 0.6026 - val_loss: 1.1587 - val_accuracy: 0.5960\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1264 - accuracy: 0.6025 - val_loss: 1.1492 - val_accuracy: 0.5998\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1220 - accuracy: 0.6050 - val_loss: 1.1698 - val_accuracy: 0.5932\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1283 - accuracy: 0.6009 - val_loss: 1.1648 - val_accuracy: 0.5918\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1328 - accuracy: 0.6006 - val_loss: 1.1384 - val_accuracy: 0.6006\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1244 - accuracy: 0.6022 - val_loss: 1.1363 - val_accuracy: 0.6010\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1310 - accuracy: 0.6004 - val_loss: 1.1839 - val_accuracy: 0.5822\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1256 - accuracy: 0.6046 - val_loss: 1.1815 - val_accuracy: 0.5904\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1251 - accuracy: 0.6028 - val_loss: 1.1692 - val_accuracy: 0.5982\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1278 - accuracy: 0.6040 - val_loss: 1.1820 - val_accuracy: 0.5876\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1317 - accuracy: 0.6013 - val_loss: 1.1605 - val_accuracy: 0.5970\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1311 - accuracy: 0.6012 - val_loss: 1.1745 - val_accuracy: 0.5886\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1220 - accuracy: 0.6093 - val_loss: 1.1632 - val_accuracy: 0.5944\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1239 - accuracy: 0.6044 - val_loss: 1.1747 - val_accuracy: 0.5946\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1247 - accuracy: 0.6040 - val_loss: 1.1558 - val_accuracy: 0.5976\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1258 - accuracy: 0.6067 - val_loss: 1.1441 - val_accuracy: 0.6038\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1247 - accuracy: 0.6022 - val_loss: 1.1601 - val_accuracy: 0.5910\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1325 - accuracy: 0.6016 - val_loss: 1.1492 - val_accuracy: 0.6042\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1313 - accuracy: 0.6017 - val_loss: 1.1597 - val_accuracy: 0.5878\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1256 - accuracy: 0.6025 - val_loss: 1.1723 - val_accuracy: 0.5864\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1279 - accuracy: 0.6058 - val_loss: 1.1645 - val_accuracy: 0.5972\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1306 - accuracy: 0.6009 - val_loss: 1.1580 - val_accuracy: 0.5882\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1216 - accuracy: 0.6060 - val_loss: 1.1939 - val_accuracy: 0.5884\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1259 - accuracy: 0.6034 - val_loss: 1.1720 - val_accuracy: 0.5902\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1240 - accuracy: 0.6050 - val_loss: 1.1649 - val_accuracy: 0.5896\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1229 - accuracy: 0.6053 - val_loss: 1.1556 - val_accuracy: 0.5986\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1221 - accuracy: 0.6026 - val_loss: 1.1566 - val_accuracy: 0.5944\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1205 - accuracy: 0.6074 - val_loss: 1.1505 - val_accuracy: 0.5944\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1304 - accuracy: 0.6007 - val_loss: 1.1513 - val_accuracy: 0.5948\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1251 - accuracy: 0.6054 - val_loss: 1.1727 - val_accuracy: 0.5930\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1254 - accuracy: 0.6050 - val_loss: 1.1655 - val_accuracy: 0.5950\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1226 - accuracy: 0.6039 - val_loss: 1.1456 - val_accuracy: 0.6026\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1215 - accuracy: 0.6013 - val_loss: 1.1594 - val_accuracy: 0.5960\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1281 - accuracy: 0.6050 - val_loss: 1.1534 - val_accuracy: 0.5982\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1248 - accuracy: 0.6020 - val_loss: 1.1403 - val_accuracy: 0.6018\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1223 - accuracy: 0.6033 - val_loss: 1.1579 - val_accuracy: 0.5852\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1195 - accuracy: 0.6052 - val_loss: 1.1417 - val_accuracy: 0.5986\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1184 - accuracy: 0.6061 - val_loss: 1.1666 - val_accuracy: 0.5920\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1209 - accuracy: 0.6082 - val_loss: 1.1457 - val_accuracy: 0.5982\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 516.3819 - accuracy: 0.2266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[516.3818969726562, 0.22660000622272491]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "    optimizer='adam', # using the Adam optimiser\n",
    "    metrics=['accuracy']) # reporting the accuracy\n",
    "model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "    batch_size=batch_size, epochs=num_epochs,\n",
    "    verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b301e95b-8623-4fb7-a470-b542c4170358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 22:47:39.406433: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 552960000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7947 - accuracy: 0.3272 - val_loss: 1.5672 - val_accuracy: 0.4178\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5365 - accuracy: 0.4304 - val_loss: 1.5045 - val_accuracy: 0.4456\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4380 - accuracy: 0.4686 - val_loss: 1.3801 - val_accuracy: 0.4870\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3702 - accuracy: 0.4964 - val_loss: 1.3725 - val_accuracy: 0.4948\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3209 - accuracy: 0.5168 - val_loss: 1.3057 - val_accuracy: 0.5208\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2807 - accuracy: 0.5359 - val_loss: 1.3196 - val_accuracy: 0.5260\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2484 - accuracy: 0.5443 - val_loss: 1.2676 - val_accuracy: 0.5358\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2161 - accuracy: 0.5570 - val_loss: 1.2898 - val_accuracy: 0.5298\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1886 - accuracy: 0.5680 - val_loss: 1.2660 - val_accuracy: 0.5356\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1627 - accuracy: 0.5768 - val_loss: 1.2552 - val_accuracy: 0.5490\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1410 - accuracy: 0.5861 - val_loss: 1.2600 - val_accuracy: 0.5506\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1214 - accuracy: 0.5926 - val_loss: 1.2177 - val_accuracy: 0.5706\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1003 - accuracy: 0.6007 - val_loss: 1.2186 - val_accuracy: 0.5646\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0834 - accuracy: 0.6070 - val_loss: 1.1893 - val_accuracy: 0.5698\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0685 - accuracy: 0.6134 - val_loss: 1.1979 - val_accuracy: 0.5692\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0528 - accuracy: 0.6189 - val_loss: 1.2236 - val_accuracy: 0.5724\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0394 - accuracy: 0.6238 - val_loss: 1.1874 - val_accuracy: 0.5736\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0225 - accuracy: 0.6300 - val_loss: 1.2295 - val_accuracy: 0.5668\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0075 - accuracy: 0.6352 - val_loss: 1.1818 - val_accuracy: 0.5818\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0012 - accuracy: 0.6361 - val_loss: 1.2209 - val_accuracy: 0.5656\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9826 - accuracy: 0.6435 - val_loss: 1.1989 - val_accuracy: 0.5756\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9736 - accuracy: 0.6479 - val_loss: 1.2465 - val_accuracy: 0.5730\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9601 - accuracy: 0.6513 - val_loss: 1.2281 - val_accuracy: 0.5800\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9461 - accuracy: 0.6559 - val_loss: 1.2362 - val_accuracy: 0.5744\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9379 - accuracy: 0.6594 - val_loss: 1.2416 - val_accuracy: 0.5778\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9223 - accuracy: 0.6629 - val_loss: 1.2268 - val_accuracy: 0.5798\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9139 - accuracy: 0.6646 - val_loss: 1.2310 - val_accuracy: 0.5748\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9048 - accuracy: 0.6691 - val_loss: 1.2230 - val_accuracy: 0.5826\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.8932 - accuracy: 0.6726 - val_loss: 1.2789 - val_accuracy: 0.5692\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8812 - accuracy: 0.6760 - val_loss: 1.2725 - val_accuracy: 0.5776\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8723 - accuracy: 0.6799 - val_loss: 1.3095 - val_accuracy: 0.5726\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.8580 - accuracy: 0.6854 - val_loss: 1.2923 - val_accuracy: 0.5830\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8471 - accuracy: 0.6875 - val_loss: 1.2854 - val_accuracy: 0.5818\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.8381 - accuracy: 0.6910 - val_loss: 1.3000 - val_accuracy: 0.5728\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8294 - accuracy: 0.6948 - val_loss: 1.2948 - val_accuracy: 0.5842\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8174 - accuracy: 0.7005 - val_loss: 1.3280 - val_accuracy: 0.5836\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.8104 - accuracy: 0.6997 - val_loss: 1.3279 - val_accuracy: 0.5694\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7947 - accuracy: 0.7076 - val_loss: 1.3613 - val_accuracy: 0.5740\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7838 - accuracy: 0.7113 - val_loss: 1.3954 - val_accuracy: 0.5750\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.7769 - accuracy: 0.7128 - val_loss: 1.3635 - val_accuracy: 0.5712\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7634 - accuracy: 0.7168 - val_loss: 1.3672 - val_accuracy: 0.5758\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7583 - accuracy: 0.7210 - val_loss: 1.4057 - val_accuracy: 0.5768\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.7406 - accuracy: 0.7256 - val_loss: 1.4830 - val_accuracy: 0.5696\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7366 - accuracy: 0.7275 - val_loss: 1.4612 - val_accuracy: 0.5656\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7256 - accuracy: 0.7306 - val_loss: 1.4644 - val_accuracy: 0.5668\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7125 - accuracy: 0.7354 - val_loss: 1.4680 - val_accuracy: 0.5706\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.7116 - accuracy: 0.7350 - val_loss: 1.4660 - val_accuracy: 0.5678\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.6927 - accuracy: 0.7418 - val_loss: 1.5219 - val_accuracy: 0.5552\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6844 - accuracy: 0.7453 - val_loss: 1.5574 - val_accuracy: 0.5616\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6791 - accuracy: 0.7471 - val_loss: 1.5548 - val_accuracy: 0.5576\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6692 - accuracy: 0.7493 - val_loss: 1.6071 - val_accuracy: 0.5632\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6629 - accuracy: 0.7530 - val_loss: 1.6080 - val_accuracy: 0.5606\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6527 - accuracy: 0.7544 - val_loss: 1.6102 - val_accuracy: 0.5576\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6452 - accuracy: 0.7586 - val_loss: 1.6591 - val_accuracy: 0.5610\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.6366 - accuracy: 0.7630 - val_loss: 1.7271 - val_accuracy: 0.5518\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.6281 - accuracy: 0.7640 - val_loss: 1.7518 - val_accuracy: 0.5472\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6227 - accuracy: 0.7660 - val_loss: 1.7924 - val_accuracy: 0.5494\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6140 - accuracy: 0.7713 - val_loss: 1.7885 - val_accuracy: 0.5650\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.6077 - accuracy: 0.7720 - val_loss: 1.7814 - val_accuracy: 0.5518\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6059 - accuracy: 0.7743 - val_loss: 1.7984 - val_accuracy: 0.5536\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5885 - accuracy: 0.7808 - val_loss: 1.8155 - val_accuracy: 0.5554\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5936 - accuracy: 0.7777 - val_loss: 1.8031 - val_accuracy: 0.5438\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5868 - accuracy: 0.7789 - val_loss: 1.8281 - val_accuracy: 0.5540\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.5744 - accuracy: 0.7857 - val_loss: 1.8924 - val_accuracy: 0.5544\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5703 - accuracy: 0.7855 - val_loss: 1.9495 - val_accuracy: 0.5454\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5584 - accuracy: 0.7911 - val_loss: 1.9087 - val_accuracy: 0.5446\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.5597 - accuracy: 0.7909 - val_loss: 1.9566 - val_accuracy: 0.5478\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.5522 - accuracy: 0.7931 - val_loss: 1.9956 - val_accuracy: 0.5412\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5432 - accuracy: 0.7941 - val_loss: 1.9412 - val_accuracy: 0.5508\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5453 - accuracy: 0.7948 - val_loss: 2.0422 - val_accuracy: 0.5406\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5381 - accuracy: 0.7981 - val_loss: 2.0541 - val_accuracy: 0.5488\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5378 - accuracy: 0.7969 - val_loss: 2.1062 - val_accuracy: 0.5468\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5270 - accuracy: 0.8031 - val_loss: 2.1949 - val_accuracy: 0.5466\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.5297 - accuracy: 0.8018 - val_loss: 2.0707 - val_accuracy: 0.5438\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5225 - accuracy: 0.8046 - val_loss: 2.1530 - val_accuracy: 0.5492\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5168 - accuracy: 0.8059 - val_loss: 2.1549 - val_accuracy: 0.5434\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.5165 - accuracy: 0.8079 - val_loss: 2.2451 - val_accuracy: 0.5422\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5012 - accuracy: 0.8119 - val_loss: 2.1983 - val_accuracy: 0.5408\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.4946 - accuracy: 0.8141 - val_loss: 2.2539 - val_accuracy: 0.5442\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5054 - accuracy: 0.8119 - val_loss: 2.2168 - val_accuracy: 0.5384\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4841 - accuracy: 0.8174 - val_loss: 2.3372 - val_accuracy: 0.5404\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4937 - accuracy: 0.8129 - val_loss: 2.2689 - val_accuracy: 0.5448\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.4861 - accuracy: 0.8177 - val_loss: 2.3034 - val_accuracy: 0.5398\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4743 - accuracy: 0.8228 - val_loss: 2.3781 - val_accuracy: 0.5344\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4810 - accuracy: 0.8200 - val_loss: 2.3141 - val_accuracy: 0.5372\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.4776 - accuracy: 0.8215 - val_loss: 2.4203 - val_accuracy: 0.5406\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4697 - accuracy: 0.8236 - val_loss: 2.4516 - val_accuracy: 0.5328\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4706 - accuracy: 0.8227 - val_loss: 2.4160 - val_accuracy: 0.5386\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.4549 - accuracy: 0.8298 - val_loss: 2.4922 - val_accuracy: 0.5374\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.4598 - accuracy: 0.8277 - val_loss: 2.4925 - val_accuracy: 0.5414\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4594 - accuracy: 0.8282 - val_loss: 2.4768 - val_accuracy: 0.5314\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4598 - accuracy: 0.8279 - val_loss: 2.5317 - val_accuracy: 0.5370\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.4480 - accuracy: 0.8332 - val_loss: 2.5779 - val_accuracy: 0.5264\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.4503 - accuracy: 0.8327 - val_loss: 2.5754 - val_accuracy: 0.5366\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.4504 - accuracy: 0.8325 - val_loss: 2.5502 - val_accuracy: 0.5338\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4471 - accuracy: 0.8338 - val_loss: 2.6154 - val_accuracy: 0.5390\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4361 - accuracy: 0.8375 - val_loss: 2.6451 - val_accuracy: 0.5284\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4377 - accuracy: 0.8360 - val_loss: 2.5690 - val_accuracy: 0.5356\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4435 - accuracy: 0.8349 - val_loss: 2.6819 - val_accuracy: 0.5302\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4386 - accuracy: 0.8355 - val_loss: 2.5340 - val_accuracy: 0.5278\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4380 - accuracy: 0.8389 - val_loss: 2.6707 - val_accuracy: 0.5374\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4336 - accuracy: 0.8384 - val_loss: 2.7182 - val_accuracy: 0.5254\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4295 - accuracy: 0.8406 - val_loss: 2.7416 - val_accuracy: 0.5312\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4276 - accuracy: 0.8409 - val_loss: 2.7515 - val_accuracy: 0.5316\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4181 - accuracy: 0.8449 - val_loss: 2.8380 - val_accuracy: 0.5402\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4202 - accuracy: 0.8446 - val_loss: 2.7395 - val_accuracy: 0.5324\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.4185 - accuracy: 0.8429 - val_loss: 2.8497 - val_accuracy: 0.5144\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4128 - accuracy: 0.8474 - val_loss: 2.7847 - val_accuracy: 0.5318\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4174 - accuracy: 0.8446 - val_loss: 2.9970 - val_accuracy: 0.5308\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4078 - accuracy: 0.8496 - val_loss: 2.8499 - val_accuracy: 0.5322\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4087 - accuracy: 0.8466 - val_loss: 2.8944 - val_accuracy: 0.5296\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4141 - accuracy: 0.8461 - val_loss: 2.9098 - val_accuracy: 0.5358\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.4007 - accuracy: 0.8518 - val_loss: 3.0174 - val_accuracy: 0.5352\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.4165 - accuracy: 0.8443 - val_loss: 2.9352 - val_accuracy: 0.5344\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.3903 - accuracy: 0.8556 - val_loss: 2.9585 - val_accuracy: 0.5172\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3967 - accuracy: 0.8518 - val_loss: 3.0164 - val_accuracy: 0.5272\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3990 - accuracy: 0.8531 - val_loss: 3.0267 - val_accuracy: 0.5360\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4047 - accuracy: 0.8506 - val_loss: 2.9655 - val_accuracy: 0.5304\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3993 - accuracy: 0.8538 - val_loss: 3.0186 - val_accuracy: 0.5230\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3954 - accuracy: 0.8534 - val_loss: 3.0844 - val_accuracy: 0.5284\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3940 - accuracy: 0.8543 - val_loss: 3.0494 - val_accuracy: 0.5264\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3908 - accuracy: 0.8560 - val_loss: 3.0681 - val_accuracy: 0.5212\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3764 - accuracy: 0.8601 - val_loss: 2.9945 - val_accuracy: 0.5302\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3997 - accuracy: 0.8551 - val_loss: 3.1316 - val_accuracy: 0.5294\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3797 - accuracy: 0.8606 - val_loss: 3.0852 - val_accuracy: 0.5240\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3842 - accuracy: 0.8582 - val_loss: 3.1970 - val_accuracy: 0.5298\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3815 - accuracy: 0.8593 - val_loss: 3.1381 - val_accuracy: 0.5328\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3844 - accuracy: 0.8601 - val_loss: 3.1129 - val_accuracy: 0.5334\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3798 - accuracy: 0.8603 - val_loss: 3.2732 - val_accuracy: 0.5224\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3679 - accuracy: 0.8645 - val_loss: 3.1738 - val_accuracy: 0.5258\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3823 - accuracy: 0.8604 - val_loss: 3.1977 - val_accuracy: 0.5284\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3887 - accuracy: 0.8569 - val_loss: 3.2964 - val_accuracy: 0.5346\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3633 - accuracy: 0.8660 - val_loss: 3.3351 - val_accuracy: 0.5174\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3700 - accuracy: 0.8611 - val_loss: 3.2592 - val_accuracy: 0.5210\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3705 - accuracy: 0.8648 - val_loss: 3.3357 - val_accuracy: 0.5280\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3689 - accuracy: 0.8638 - val_loss: 3.3627 - val_accuracy: 0.5224\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3731 - accuracy: 0.8655 - val_loss: 3.2841 - val_accuracy: 0.5236\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3694 - accuracy: 0.8641 - val_loss: 3.4703 - val_accuracy: 0.5308\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3752 - accuracy: 0.8625 - val_loss: 3.3473 - val_accuracy: 0.5330\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3758 - accuracy: 0.8615 - val_loss: 3.3406 - val_accuracy: 0.5260\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3666 - accuracy: 0.8663 - val_loss: 3.3494 - val_accuracy: 0.5118\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3699 - accuracy: 0.8637 - val_loss: 3.4150 - val_accuracy: 0.5160\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3617 - accuracy: 0.8669 - val_loss: 3.4511 - val_accuracy: 0.5230\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3558 - accuracy: 0.8685 - val_loss: 3.3646 - val_accuracy: 0.5304\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3627 - accuracy: 0.8684 - val_loss: 3.5098 - val_accuracy: 0.5202\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3526 - accuracy: 0.8718 - val_loss: 3.4071 - val_accuracy: 0.5122\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3735 - accuracy: 0.8645 - val_loss: 3.3506 - val_accuracy: 0.5172\n",
      "Epoch 148/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3640 - accuracy: 0.8681 - val_loss: 3.4712 - val_accuracy: 0.5312\n",
      "Epoch 149/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3408 - accuracy: 0.8765 - val_loss: 3.5659 - val_accuracy: 0.5234\n",
      "Epoch 150/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3572 - accuracy: 0.8702 - val_loss: 3.4972 - val_accuracy: 0.5192\n",
      "Epoch 151/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3638 - accuracy: 0.8681 - val_loss: 3.4571 - val_accuracy: 0.5196\n",
      "Epoch 152/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3566 - accuracy: 0.8702 - val_loss: 3.4130 - val_accuracy: 0.5224\n",
      "Epoch 153/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3609 - accuracy: 0.8680 - val_loss: 3.5665 - val_accuracy: 0.5174\n",
      "Epoch 154/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3472 - accuracy: 0.8740 - val_loss: 3.5172 - val_accuracy: 0.5246\n",
      "Epoch 155/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3408 - accuracy: 0.8764 - val_loss: 3.4884 - val_accuracy: 0.5220\n",
      "Epoch 156/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3585 - accuracy: 0.8704 - val_loss: 3.5902 - val_accuracy: 0.5202\n",
      "Epoch 157/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3464 - accuracy: 0.8716 - val_loss: 3.5152 - val_accuracy: 0.5224\n",
      "Epoch 158/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3443 - accuracy: 0.8741 - val_loss: 3.6185 - val_accuracy: 0.5192\n",
      "Epoch 159/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3433 - accuracy: 0.8764 - val_loss: 3.6202 - val_accuracy: 0.5244\n",
      "Epoch 160/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3437 - accuracy: 0.8746 - val_loss: 3.6812 - val_accuracy: 0.5228\n",
      "Epoch 161/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3414 - accuracy: 0.8744 - val_loss: 3.6109 - val_accuracy: 0.5204\n",
      "Epoch 162/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3481 - accuracy: 0.8739 - val_loss: 3.5983 - val_accuracy: 0.5156\n",
      "Epoch 163/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3517 - accuracy: 0.8726 - val_loss: 3.6118 - val_accuracy: 0.5240\n",
      "Epoch 164/200\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3406 - accuracy: 0.8765 - val_loss: 3.8271 - val_accuracy: 0.5170\n",
      "Epoch 165/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3427 - accuracy: 0.8741 - val_loss: 3.7527 - val_accuracy: 0.5296\n",
      "Epoch 166/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3275 - accuracy: 0.8801 - val_loss: 3.8380 - val_accuracy: 0.5194\n",
      "Epoch 167/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.3667 - accuracy: 0.8696 - val_loss: 3.8212 - val_accuracy: 0.5246\n",
      "Epoch 168/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3336 - accuracy: 0.8798 - val_loss: 3.5759 - val_accuracy: 0.5202\n",
      "Epoch 169/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3335 - accuracy: 0.8800 - val_loss: 3.7106 - val_accuracy: 0.5258\n",
      "Epoch 170/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3373 - accuracy: 0.8773 - val_loss: 3.7149 - val_accuracy: 0.5154\n",
      "Epoch 171/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3428 - accuracy: 0.8771 - val_loss: 3.7150 - val_accuracy: 0.5224\n",
      "Epoch 172/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3375 - accuracy: 0.8781 - val_loss: 3.8624 - val_accuracy: 0.5248\n",
      "Epoch 173/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3196 - accuracy: 0.8832 - val_loss: 3.7537 - val_accuracy: 0.5238\n",
      "Epoch 174/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3582 - accuracy: 0.8733 - val_loss: 3.8071 - val_accuracy: 0.5192\n",
      "Epoch 175/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3289 - accuracy: 0.8822 - val_loss: 3.8002 - val_accuracy: 0.5222\n",
      "Epoch 176/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3309 - accuracy: 0.8817 - val_loss: 3.8100 - val_accuracy: 0.5282\n",
      "Epoch 177/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3265 - accuracy: 0.8820 - val_loss: 3.7927 - val_accuracy: 0.5252\n",
      "Epoch 178/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3307 - accuracy: 0.8792 - val_loss: 3.7014 - val_accuracy: 0.5186\n",
      "Epoch 179/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3320 - accuracy: 0.8806 - val_loss: 3.9379 - val_accuracy: 0.5268\n",
      "Epoch 180/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3307 - accuracy: 0.8814 - val_loss: 3.7953 - val_accuracy: 0.5248\n",
      "Epoch 181/200\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3399 - accuracy: 0.8786 - val_loss: 3.8539 - val_accuracy: 0.5152\n",
      "Epoch 182/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3353 - accuracy: 0.8805 - val_loss: 3.9345 - val_accuracy: 0.5258\n",
      "Epoch 183/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.3215 - accuracy: 0.8849 - val_loss: 3.7628 - val_accuracy: 0.5244\n",
      "Epoch 184/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3397 - accuracy: 0.8796 - val_loss: 4.0282 - val_accuracy: 0.5214\n",
      "Epoch 185/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.3343 - accuracy: 0.8808 - val_loss: 3.9929 - val_accuracy: 0.5208\n",
      "Epoch 186/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.3401 - accuracy: 0.8795 - val_loss: 3.8809 - val_accuracy: 0.5126\n",
      "Epoch 187/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.3324 - accuracy: 0.8831 - val_loss: 3.9442 - val_accuracy: 0.5138\n",
      "Epoch 188/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.3288 - accuracy: 0.8827 - val_loss: 4.0879 - val_accuracy: 0.5112\n",
      "Epoch 189/200\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.3152 - accuracy: 0.8866 - val_loss: 3.9535 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3170 - accuracy: 0.8860 - val_loss: 3.8418 - val_accuracy: 0.5156\n",
      "Epoch 191/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.3366 - accuracy: 0.8787 - val_loss: 3.9933 - val_accuracy: 0.5256\n",
      "Epoch 192/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.3204 - accuracy: 0.8857 - val_loss: 4.0264 - val_accuracy: 0.5164\n",
      "Epoch 193/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.3300 - accuracy: 0.8818 - val_loss: 4.0598 - val_accuracy: 0.5194\n",
      "Epoch 194/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.3217 - accuracy: 0.8832 - val_loss: 3.9910 - val_accuracy: 0.5168\n",
      "Epoch 195/200\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3249 - accuracy: 0.8837 - val_loss: 4.0949 - val_accuracy: 0.5230\n",
      "Epoch 196/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3277 - accuracy: 0.8857 - val_loss: 4.1245 - val_accuracy: 0.5200\n",
      "Epoch 197/200\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3291 - accuracy: 0.8833 - val_loss: 4.0619 - val_accuracy: 0.5136\n",
      "Epoch 198/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.3269 - accuracy: 0.8853 - val_loss: 3.9118 - val_accuracy: 0.5232\n",
      "Epoch 199/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3061 - accuracy: 0.8896 - val_loss: 3.9000 - val_accuracy: 0.5186\n",
      "Epoch 200/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3228 - accuracy: 0.8839 - val_loss: 4.0540 - val_accuracy: 0.5140\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2503.4097 - accuracy: 0.2035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2503.40966796875, 0.20350000262260437]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size,  kernel_size, padding='same', activation='relu')(input1)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(pool_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
    "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(pool_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "output1 = Dense(num_classes, activation='softmax')(hidden)\n",
    "model1 = Model(inputs=input1, outputs=output1) # To define a model, just specify its input and output layers\n",
    "model1.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "  optimizer='adam', # using the Adam optimiser\n",
    "  metrics=['accuracy']) # reporting the accuracy\n",
    "model1.fit(X_train, Y_train, # Train the model using the training set...\n",
    "  batch_size=batch_size, epochs=num_epochs,\n",
    "  verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "model1.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ee77e-8177-459a-847b-b0f75b456c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:40:55.761479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-05 12:40:55.761527: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-05 12:40:55.761556: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (macbook-pro): /proc/driver/nvidia/version does not exist\n",
      "2022-04-05 12:40:55.761878: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:40:56.411817: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 552960000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 9ms/step - loss: 1.7858 - accuracy: 0.3308 - val_loss: 1.4904 - val_accuracy: 0.4478\n",
      "Epoch 2/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5343 - accuracy: 0.4332 - val_loss: 1.3545 - val_accuracy: 0.4986\n",
      "Epoch 3/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4523 - accuracy: 0.4679 - val_loss: 1.2928 - val_accuracy: 0.5206\n",
      "Epoch 4/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3959 - accuracy: 0.4937 - val_loss: 1.2362 - val_accuracy: 0.5470\n",
      "Epoch 5/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3561 - accuracy: 0.5104 - val_loss: 1.2133 - val_accuracy: 0.5584\n",
      "Epoch 6/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3266 - accuracy: 0.5219 - val_loss: 1.2108 - val_accuracy: 0.5718\n",
      "Epoch 7/200\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3002 - accuracy: 0.5328 - val_loss: 1.1679 - val_accuracy: 0.5798\n",
      "Epoch 8/200\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.2848 - accuracy: 0.5388 - val_loss: 1.1372 - val_accuracy: 0.5912\n",
      "Epoch 9/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2567 - accuracy: 0.5506 - val_loss: 1.1349 - val_accuracy: 0.5910\n",
      "Epoch 10/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2481 - accuracy: 0.5550 - val_loss: 1.1254 - val_accuracy: 0.5992\n",
      "Epoch 11/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2251 - accuracy: 0.5599 - val_loss: 1.1070 - val_accuracy: 0.6102\n",
      "Epoch 12/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2141 - accuracy: 0.5650 - val_loss: 1.0798 - val_accuracy: 0.6122\n",
      "Epoch 13/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2043 - accuracy: 0.5715 - val_loss: 1.1078 - val_accuracy: 0.6028\n",
      "Epoch 14/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1973 - accuracy: 0.5729 - val_loss: 1.0903 - val_accuracy: 0.6138\n",
      "Epoch 15/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1907 - accuracy: 0.5746 - val_loss: 1.0808 - val_accuracy: 0.6192\n",
      "Epoch 16/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1789 - accuracy: 0.5806 - val_loss: 1.0654 - val_accuracy: 0.6232\n",
      "Epoch 17/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1775 - accuracy: 0.5800 - val_loss: 1.0635 - val_accuracy: 0.6180\n",
      "Epoch 18/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1629 - accuracy: 0.5848 - val_loss: 1.0961 - val_accuracy: 0.6112\n",
      "Epoch 19/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1604 - accuracy: 0.5863 - val_loss: 1.1000 - val_accuracy: 0.6066\n",
      "Epoch 20/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1548 - accuracy: 0.5886 - val_loss: 1.0603 - val_accuracy: 0.6276\n",
      "Epoch 21/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1437 - accuracy: 0.5919 - val_loss: 1.0638 - val_accuracy: 0.6264\n",
      "Epoch 22/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1418 - accuracy: 0.5943 - val_loss: 1.0562 - val_accuracy: 0.6318\n",
      "Epoch 23/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1312 - accuracy: 0.5974 - val_loss: 1.0487 - val_accuracy: 0.6358\n",
      "Epoch 24/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1317 - accuracy: 0.5976 - val_loss: 1.0687 - val_accuracy: 0.6230\n",
      "Epoch 25/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1292 - accuracy: 0.5976 - val_loss: 1.0398 - val_accuracy: 0.6344\n",
      "Epoch 26/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1255 - accuracy: 0.6028 - val_loss: 1.0326 - val_accuracy: 0.6356\n",
      "Epoch 27/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1202 - accuracy: 0.6001 - val_loss: 1.0293 - val_accuracy: 0.6452\n",
      "Epoch 28/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1143 - accuracy: 0.6050 - val_loss: 1.0315 - val_accuracy: 0.6360\n",
      "Epoch 29/200\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1138 - accuracy: 0.6036 - val_loss: 1.0226 - val_accuracy: 0.6450\n",
      "Epoch 30/200\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1067 - accuracy: 0.6074 - val_loss: 1.0116 - val_accuracy: 0.6444\n",
      "Epoch 31/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0962 - accuracy: 0.6140 - val_loss: 1.0183 - val_accuracy: 0.6386\n",
      "Epoch 32/200\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.1048 - accuracy: 0.6051 - val_loss: 1.0315 - val_accuracy: 0.6410\n",
      "Epoch 33/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0962 - accuracy: 0.6123 - val_loss: 1.0099 - val_accuracy: 0.6546\n",
      "Epoch 34/200\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0951 - accuracy: 0.6129 - val_loss: 1.0155 - val_accuracy: 0.6514\n",
      "Epoch 35/200\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.0920 - accuracy: 0.6116 - val_loss: 1.0014 - val_accuracy: 0.6464\n",
      "Epoch 36/200\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0901 - accuracy: 0.6111 - val_loss: 1.0166 - val_accuracy: 0.6432\n",
      "Epoch 37/200\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0909 - accuracy: 0.6142 - val_loss: 1.0290 - val_accuracy: 0.6378\n",
      "Epoch 38/200\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0802 - accuracy: 0.6167 - val_loss: 1.0174 - val_accuracy: 0.6432\n",
      "Epoch 39/200\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.0847 - accuracy: 0.6160 - val_loss: 1.0231 - val_accuracy: 0.6430\n",
      "Epoch 40/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0757 - accuracy: 0.6169 - val_loss: 0.9995 - val_accuracy: 0.6616\n",
      "Epoch 41/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0762 - accuracy: 0.6181 - val_loss: 1.0061 - val_accuracy: 0.6550\n",
      "Epoch 42/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0698 - accuracy: 0.6194 - val_loss: 1.0237 - val_accuracy: 0.6404\n",
      "Epoch 43/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0699 - accuracy: 0.6191 - val_loss: 1.0059 - val_accuracy: 0.6522\n",
      "Epoch 44/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0727 - accuracy: 0.6197 - val_loss: 1.0049 - val_accuracy: 0.6530\n",
      "Epoch 45/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0642 - accuracy: 0.6212 - val_loss: 1.0115 - val_accuracy: 0.6486\n",
      "Epoch 46/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0618 - accuracy: 0.6220 - val_loss: 1.0131 - val_accuracy: 0.6488\n",
      "Epoch 47/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0647 - accuracy: 0.6218 - val_loss: 0.9949 - val_accuracy: 0.6576\n",
      "Epoch 48/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0645 - accuracy: 0.6201 - val_loss: 1.0026 - val_accuracy: 0.6516\n",
      "Epoch 49/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0672 - accuracy: 0.6208 - val_loss: 1.0298 - val_accuracy: 0.6418\n",
      "Epoch 50/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0567 - accuracy: 0.6248 - val_loss: 1.0109 - val_accuracy: 0.6456\n",
      "Epoch 51/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0582 - accuracy: 0.6259 - val_loss: 1.0059 - val_accuracy: 0.6548\n",
      "Epoch 52/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0591 - accuracy: 0.6254 - val_loss: 0.9899 - val_accuracy: 0.6590\n",
      "Epoch 53/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0591 - accuracy: 0.6239 - val_loss: 0.9979 - val_accuracy: 0.6610\n",
      "Epoch 54/200\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.0556 - accuracy: 0.6243 - val_loss: 1.0176 - val_accuracy: 0.6502\n",
      "Epoch 55/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0530 - accuracy: 0.6255 - val_loss: 1.0138 - val_accuracy: 0.6504\n",
      "Epoch 56/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0496 - accuracy: 0.6270 - val_loss: 0.9886 - val_accuracy: 0.6586\n",
      "Epoch 57/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0519 - accuracy: 0.6261 - val_loss: 1.0262 - val_accuracy: 0.6404\n",
      "Epoch 58/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0490 - accuracy: 0.6284 - val_loss: 1.0050 - val_accuracy: 0.6546\n",
      "Epoch 59/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0547 - accuracy: 0.6278 - val_loss: 1.0194 - val_accuracy: 0.6436\n",
      "Epoch 60/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0463 - accuracy: 0.6305 - val_loss: 0.9925 - val_accuracy: 0.6538\n",
      "Epoch 61/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0465 - accuracy: 0.6304 - val_loss: 0.9951 - val_accuracy: 0.6494\n",
      "Epoch 62/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0450 - accuracy: 0.6284 - val_loss: 0.9805 - val_accuracy: 0.6668\n",
      "Epoch 63/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0418 - accuracy: 0.6311 - val_loss: 0.9839 - val_accuracy: 0.6606\n",
      "Epoch 64/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0341 - accuracy: 0.6309 - val_loss: 0.9950 - val_accuracy: 0.6420\n",
      "Epoch 65/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0393 - accuracy: 0.6346 - val_loss: 0.9819 - val_accuracy: 0.6634\n",
      "Epoch 66/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0330 - accuracy: 0.6327 - val_loss: 1.0043 - val_accuracy: 0.6526\n",
      "Epoch 67/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0379 - accuracy: 0.6328 - val_loss: 0.9984 - val_accuracy: 0.6524\n",
      "Epoch 68/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0420 - accuracy: 0.6304 - val_loss: 0.9982 - val_accuracy: 0.6584\n",
      "Epoch 69/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0355 - accuracy: 0.6371 - val_loss: 0.9882 - val_accuracy: 0.6592\n",
      "Epoch 70/200\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0327 - accuracy: 0.6342 - val_loss: 0.9920 - val_accuracy: 0.6464\n",
      "Epoch 71/200\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0247 - accuracy: 0.6390 - val_loss: 1.0041 - val_accuracy: 0.6638\n",
      "Epoch 72/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0321 - accuracy: 0.6343 - val_loss: 0.9882 - val_accuracy: 0.6562\n",
      "Epoch 73/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0241 - accuracy: 0.6350 - val_loss: 0.9833 - val_accuracy: 0.6600\n",
      "Epoch 74/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0287 - accuracy: 0.6373 - val_loss: 0.9919 - val_accuracy: 0.6604\n",
      "Epoch 75/200\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0248 - accuracy: 0.6382 - val_loss: 0.9940 - val_accuracy: 0.6626\n",
      "Epoch 76/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0245 - accuracy: 0.6378 - val_loss: 0.9809 - val_accuracy: 0.6626\n",
      "Epoch 77/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0226 - accuracy: 0.6374 - val_loss: 0.9803 - val_accuracy: 0.6624\n",
      "Epoch 78/200\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0218 - accuracy: 0.6378 - val_loss: 0.9909 - val_accuracy: 0.6634\n",
      "Epoch 79/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0197 - accuracy: 0.6381 - val_loss: 0.9860 - val_accuracy: 0.6516\n",
      "Epoch 80/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0233 - accuracy: 0.6403 - val_loss: 0.9771 - val_accuracy: 0.6606\n",
      "Epoch 81/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0270 - accuracy: 0.6367 - val_loss: 0.9804 - val_accuracy: 0.6652\n",
      "Epoch 82/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0186 - accuracy: 0.6409 - val_loss: 0.9794 - val_accuracy: 0.6672\n",
      "Epoch 83/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0153 - accuracy: 0.6409 - val_loss: 0.9953 - val_accuracy: 0.6578\n",
      "Epoch 84/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0142 - accuracy: 0.6398 - val_loss: 0.9892 - val_accuracy: 0.6564\n",
      "Epoch 85/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0112 - accuracy: 0.6419 - val_loss: 0.9776 - val_accuracy: 0.6618\n",
      "Epoch 86/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0162 - accuracy: 0.6417 - val_loss: 0.9861 - val_accuracy: 0.6596\n",
      "Epoch 87/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0175 - accuracy: 0.6424 - val_loss: 0.9677 - val_accuracy: 0.6662\n",
      "Epoch 88/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0215 - accuracy: 0.6421 - val_loss: 0.9942 - val_accuracy: 0.6674\n",
      "Epoch 89/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0225 - accuracy: 0.6410 - val_loss: 0.9948 - val_accuracy: 0.6526\n",
      "Epoch 90/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0112 - accuracy: 0.6438 - val_loss: 1.0009 - val_accuracy: 0.6534\n",
      "Epoch 91/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0135 - accuracy: 0.6432 - val_loss: 0.9911 - val_accuracy: 0.6606\n",
      "Epoch 92/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0178 - accuracy: 0.6404 - val_loss: 0.9874 - val_accuracy: 0.6616\n",
      "Epoch 93/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0065 - accuracy: 0.6422 - val_loss: 1.0330 - val_accuracy: 0.6352\n",
      "Epoch 94/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0116 - accuracy: 0.6456 - val_loss: 0.9986 - val_accuracy: 0.6628\n",
      "Epoch 95/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0110 - accuracy: 0.6469 - val_loss: 0.9698 - val_accuracy: 0.6628\n",
      "Epoch 96/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0102 - accuracy: 0.6443 - val_loss: 0.9686 - val_accuracy: 0.6666\n",
      "Epoch 97/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0077 - accuracy: 0.6442 - val_loss: 0.9702 - val_accuracy: 0.6674\n",
      "Epoch 98/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0093 - accuracy: 0.6444 - val_loss: 0.9572 - val_accuracy: 0.6700\n",
      "Epoch 99/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0061 - accuracy: 0.6466 - val_loss: 1.0007 - val_accuracy: 0.6456\n",
      "Epoch 100/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0030 - accuracy: 0.6469 - val_loss: 0.9820 - val_accuracy: 0.6648\n",
      "Epoch 101/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0098 - accuracy: 0.6441 - val_loss: 0.9704 - val_accuracy: 0.6616\n",
      "Epoch 102/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9996 - accuracy: 0.6468 - val_loss: 0.9532 - val_accuracy: 0.6686\n",
      "Epoch 103/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9985 - accuracy: 0.6462 - val_loss: 0.9613 - val_accuracy: 0.6632\n",
      "Epoch 104/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0020 - accuracy: 0.6465 - val_loss: 0.9714 - val_accuracy: 0.6582\n",
      "Epoch 105/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9995 - accuracy: 0.6477 - val_loss: 0.9702 - val_accuracy: 0.6654\n",
      "Epoch 106/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0040 - accuracy: 0.6473 - val_loss: 0.9842 - val_accuracy: 0.6662\n",
      "Epoch 107/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0001 - accuracy: 0.6474 - val_loss: 0.9726 - val_accuracy: 0.6624\n",
      "Epoch 108/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9986 - accuracy: 0.6474 - val_loss: 0.9929 - val_accuracy: 0.6604\n",
      "Epoch 109/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9983 - accuracy: 0.6494 - val_loss: 0.9958 - val_accuracy: 0.6474\n",
      "Epoch 110/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0005 - accuracy: 0.6464 - val_loss: 0.9856 - val_accuracy: 0.6592\n",
      "Epoch 111/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0034 - accuracy: 0.6462 - val_loss: 0.9757 - val_accuracy: 0.6612\n",
      "Epoch 112/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0026 - accuracy: 0.6463 - val_loss: 0.9815 - val_accuracy: 0.6632\n",
      "Epoch 113/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9940 - accuracy: 0.6495 - val_loss: 0.9742 - val_accuracy: 0.6644\n",
      "Epoch 114/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9894 - accuracy: 0.6526 - val_loss: 0.9635 - val_accuracy: 0.6704\n",
      "Epoch 115/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0001 - accuracy: 0.6479 - val_loss: 0.9759 - val_accuracy: 0.6602\n",
      "Epoch 116/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9969 - accuracy: 0.6488 - val_loss: 0.9625 - val_accuracy: 0.6626\n",
      "Epoch 117/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9967 - accuracy: 0.6498 - val_loss: 0.9649 - val_accuracy: 0.6710\n",
      "Epoch 118/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0010 - accuracy: 0.6481 - val_loss: 0.9818 - val_accuracy: 0.6594\n",
      "Epoch 119/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0011 - accuracy: 0.6448 - val_loss: 0.9769 - val_accuracy: 0.6624\n",
      "Epoch 120/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9978 - accuracy: 0.6522 - val_loss: 0.9568 - val_accuracy: 0.6662\n",
      "Epoch 121/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9947 - accuracy: 0.6496 - val_loss: 0.9689 - val_accuracy: 0.6590\n",
      "Epoch 122/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9951 - accuracy: 0.6498 - val_loss: 0.9556 - val_accuracy: 0.6600\n",
      "Epoch 123/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9940 - accuracy: 0.6496 - val_loss: 0.9624 - val_accuracy: 0.6722\n",
      "Epoch 124/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9936 - accuracy: 0.6502 - val_loss: 0.9797 - val_accuracy: 0.6572\n",
      "Epoch 125/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9976 - accuracy: 0.6494 - val_loss: 0.9731 - val_accuracy: 0.6628\n",
      "Epoch 126/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9856 - accuracy: 0.6548 - val_loss: 0.9600 - val_accuracy: 0.6604\n",
      "Epoch 127/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9939 - accuracy: 0.6515 - val_loss: 0.9900 - val_accuracy: 0.6572\n",
      "Epoch 128/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9912 - accuracy: 0.6508 - val_loss: 0.9733 - val_accuracy: 0.6624\n",
      "Epoch 129/200\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9906 - accuracy: 0.6508 - val_loss: 0.9470 - val_accuracy: 0.6736\n",
      "Epoch 130/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9889 - accuracy: 0.6517 - val_loss: 0.9617 - val_accuracy: 0.6726\n",
      "Epoch 131/200\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9881 - accuracy: 0.6520 - val_loss: 0.9613 - val_accuracy: 0.6614\n",
      "Epoch 132/200\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9855 - accuracy: 0.6532 - val_loss: 0.9694 - val_accuracy: 0.6670\n",
      "Epoch 133/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9880 - accuracy: 0.6502 - val_loss: 0.9772 - val_accuracy: 0.6644\n",
      "Epoch 134/200\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9879 - accuracy: 0.6516 - val_loss: 0.9764 - val_accuracy: 0.6650\n",
      "Epoch 135/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9863 - accuracy: 0.6528 - val_loss: 0.9605 - val_accuracy: 0.6670\n",
      "Epoch 136/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9796 - accuracy: 0.6542 - val_loss: 0.9789 - val_accuracy: 0.6642\n",
      "Epoch 137/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9868 - accuracy: 0.6533 - val_loss: 0.9645 - val_accuracy: 0.6670\n",
      "Epoch 138/200\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9835 - accuracy: 0.6538 - val_loss: 0.9534 - val_accuracy: 0.6736\n",
      "Epoch 139/200\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9823 - accuracy: 0.6558 - val_loss: 0.9569 - val_accuracy: 0.6752\n",
      "Epoch 140/200\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9844 - accuracy: 0.6567 - val_loss: 1.0025 - val_accuracy: 0.6570\n",
      "Epoch 141/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9834 - accuracy: 0.6556 - val_loss: 0.9643 - val_accuracy: 0.6720\n",
      "Epoch 142/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9857 - accuracy: 0.6545 - val_loss: 0.9611 - val_accuracy: 0.6650\n",
      "Epoch 143/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9817 - accuracy: 0.6556 - val_loss: 0.9788 - val_accuracy: 0.6618\n",
      "Epoch 144/200\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9871 - accuracy: 0.6541 - val_loss: 0.9747 - val_accuracy: 0.6606\n",
      "Epoch 145/200\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9792 - accuracy: 0.6561 - val_loss: 0.9497 - val_accuracy: 0.6780\n",
      "Epoch 146/200\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9840 - accuracy: 0.6540 - val_loss: 0.9614 - val_accuracy: 0.6696\n",
      "Epoch 147/200\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9819 - accuracy: 0.6555 - val_loss: 0.9621 - val_accuracy: 0.6650\n",
      "Epoch 148/200\n",
      " 495/1407 [=========>....................] - ETA: 10s - loss: 0.9680 - accuracy: 0.6590"
     ]
    }
   ],
   "source": [
    "kernel_size1 = 2 # we will use 3x3 kernels throughout\n",
    "\n",
    "inp2 = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size1, kernel_size1, padding='same', activation='relu')(inp2)\n",
    "conv_2 = Convolution2D(conv_depth_1, kernel_size1, kernel_size1, padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, kernel_size1, kernel_size1, padding='same', activation='relu')(drop_1)\n",
    "conv_4 = Convolution2D(conv_depth_2, kernel_size1, kernel_size1, padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding = 'same')(conv_4)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out2 = Dense(num_classes, activation='softmax')(drop_3)\n",
    "model2 = Model(inputs=inp2, outputs=out2) # To define a model, just specify its input and output layers\n",
    "model2.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "    optimizer='adam', # using the Adam optimiser\n",
    "    metrics=['accuracy']) # reporting the accuracy\n",
    "model2.fit(X_train, Y_train, # Train the model using the training set...\n",
    "    batch_size=batch_size, epochs=num_epochs,\n",
    "    verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "model2.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdedf45-cb03-406e-9bf6-ba3a32d492bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
